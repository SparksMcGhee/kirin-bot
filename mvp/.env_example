# Slack API Configuration
SLACK_BOT_TOKEN=xoxb-your-slack-bot-token-here
SLACK_CHANNEL_IDS=C1234567890,C0987654321
SLACK_LOOKBACK_HOURS=24

# Ollama Configuration
# With 128GB unified memory, you can run much larger models than the default.
# Recommended models for summarization (in order of quality):
# - llama3.1:8b (default) - Excellent quality, fast inference, ~4.7GB VRAM
# - llama3.1:70b - Maximum quality, slower, ~40GB VRAM (well within your capacity)
# - mistral:7b - Great alternative, ~4.1GB VRAM
# - qwen2.5:14b - Excellent for summarization, ~8GB VRAM
# - qwen2.5:32b - Very high quality, ~18GB VRAM
# Smaller models (if you want faster inference):
# - llama3.2:3b - Good quality, very fast, ~2GB VRAM
# - llama3.2:1b - Fastest but limited capability, ~0.6GB VRAM
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=qwen2.5:32b

# Output Configuration
OUTPUT_DIR=/app/output
OUTPUT_FILENAME=slack-summary.txt

# Logging
LOG_LEVEL=info

# Ansible Deployment Configuration
# These variables are used by Ansible inventory.yml
ANSIBLE_HOST=your.server.ip.address
ANSIBLE_USER=your_username
ANSIBLE_SSH_KEY=~/.ssh/your_key
# Optional: if using password authentication
# ANSIBLE_PASSWORD=your_password
